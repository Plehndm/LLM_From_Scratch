{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ebcc8a-3863-48ea-a3d0-f7ed7678b329",
   "metadata": {},
   "source": [
    "# Building an LLM from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd4213f-24bb-47b1-acc8-87c64b7c4ba5",
   "metadata": {},
   "source": [
    "### Uncomment line below if torch is not already installed in your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08c8088-f065-4963-bea1-d8b2a9461df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8ab067-57b9-40d8-a57e-f3f1345083b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eab09e-da10-4154-afa5-3d56daea1d67",
   "metadata": {},
   "source": [
    "### I want to test how a basic Neural Network functions, so I'm creating a basic Neural Network with only a few layers to experiment with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4417e834-23de-4813-a603-ecd458595f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "\n",
    "            # 1st hidden layer\n",
    "            torch.nn.Linear(num_inputs, 30), # Linear layer takes the number of input and output nodes as arguments\n",
    "            torch.nn.ReLU(),                 # Nonlinear activation functions are placed between the hidden layers\n",
    "    \n",
    "            # 2nd hidden layer\n",
    "            torch.nn.Linear(30, 20),         # The number of output nodes of one hidden layer had to match the number of input nodes of the next layer\n",
    "            torch.nn.ReLU(),\n",
    "    \n",
    "            # Output layer\n",
    "            torch.nn.Linear(20, num_outputs)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits                        # The outputs of the last layer are called logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f098b3-a125-4356-89b9-f00ad08ad159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(50, 3)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcb8f40-994f-43f0-8afb-245a786cebe5",
   "metadata": {},
   "source": [
    "### As a core part of training AI models is gradient descent through  I want to analyze the structure of the parameters that will be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a741c7-f971-467b-8008-e72c9e2ce710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable model parameters: 2213\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of trainable model parameters:\", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e31bb03-c7d6-4642-8afa-7b79934d4e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0334,  0.1269,  0.1080,  ..., -0.1135, -0.1335,  0.1115],\n",
      "        [-0.0968, -0.0664,  0.0215,  ..., -0.0666, -0.0634, -0.0421],\n",
      "        [ 0.1287,  0.0971, -0.0989,  ..., -0.0694,  0.0166, -0.0071],\n",
      "        ...,\n",
      "        [ 0.1235, -0.0045,  0.1107,  ...,  0.1009,  0.0674, -0.0080],\n",
      "        [ 0.0961,  0.0807, -0.1186,  ...,  0.0144, -0.1199,  0.0450],\n",
      "        [ 0.0370, -0.0577,  0.1146,  ..., -0.0860, -0.1162, -0.1088]],\n",
      "       requires_grad=True)\n",
      "torch.Size([30, 50])\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weight)\n",
    "print(model.layers[0].weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac5615dd-5131-4f52-a00d-784314fbd408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
      "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
      "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
      "        ...,\n",
      "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
      "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
      "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(50, 3)\n",
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c21aa5-156d-47ad-9800-feb426ca67f5",
   "metadata": {},
   "source": [
    "### When a gradient is computed within the model it keeps track of each operation for the calculation of the parameters partial derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "557d30d9-f9a6-4449-976c-dc5b45ff9ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "X = torch.rand((1, 50))\n",
    "out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ae996cf-fda7-49fa-bcbe-aa9049d2f7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1262,  0.1080, -0.1792]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04962d82-8dcc-4b80-a7fe-49cc483d9d84",
   "metadata": {},
   "source": [
    "### Initializing testing data to experiment with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05400fe8-7395-467e-86b3-00d8cb985a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor([\n",
    "    [-1.2, 3.1],\n",
    "    [-0.9, 2.9],\n",
    "    [-0.5, 2.6],\n",
    "    [2.3, -1.1],\n",
    "    [2.7, -1.5]\n",
    "])\n",
    "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
    "\n",
    "X_test = torch.tensor([\n",
    "    [-0.8, 2.8],\n",
    "    [2.6, -1.6],\n",
    "])\n",
    "y_test = torch.tensor([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c52ad364-2e27-4060-a81a-d260d41cc268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.features = X\n",
    "        self.labels = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        one_x = self.features[index]\n",
    "        one_y = self.labels[index]\n",
    "        return one_x, one_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dabeb20a-66a3-46f4-a588-758f346e09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ToyDataset(X_train, y_train)\n",
    "test_ds = ToyDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca15a30e-1381-4955-ae8c-56030dfb0154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00666609-677e-4707-8f8d-63799e9d08f2",
   "metadata": {},
   "source": [
    "### In order to make the process of training more streamlined im creating a simple DataLoader which will handle the batching among other data preprocessing when used while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cac1cf1-bf36-4d74-98f7-343ef51745fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0        # The number of subprocesses used to batch the dataset: useful for large datasets and allows GPU to batch while CPU prepares\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0751e621-c260-45ca-8494-61b784079117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "Batch 2: tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Batch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\", x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93867d8c-1d57-4012-9b5e-a4c73c52a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having a substantially smaller batch as the last batch in a training epoch can disturb the convergence during training.\n",
    "# To prevent this we will set drop_last=True.\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af3e08bf-7d66-4bb3-afcd-b60e22345f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Batch 2: tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\", x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb53f8-de0c-4e9c-8c6b-f9e787698506",
   "metadata": {},
   "source": [
    "### Creating the training loop and examining the process and loss outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9b368be-81ec-4e94-9a9d-50b242eeef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/003 | Batch 001/002 | Train Loss: 0.75\n",
      "Epoch: 001/003 | Batch 002/002 | Train Loss: 0.65\n",
      "Epoch: 002/003 | Batch 001/002 | Train Loss: 0.44\n",
      "Epoch: 002/003 | Batch 002/002 | Train Loss: 0.13\n",
      "Epoch: 003/003 | Batch 001/002 | Train Loss: 0.03\n",
      "Epoch: 003/003 | Batch 002/002 | Train Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(num_inputs=2, num_outputs=2) # The toy dataset has 2 features and 2 classes\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=0.5                     # The optimizer needs to know which parameters to optimize\n",
    ")\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "        logits = model(features)\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()                     # Sets the gradients from the previous round to 0 to prevent unintended gradient accumulation\n",
    "        loss.backward()                           # Computes the gradients of the loss given the model parameters\n",
    "        optimizer.step()                          # The optimizer used the gradients to update the model parameters\n",
    "\n",
    "        ## LOGGING\n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
    "              f\" | Batch {batch_idx+1:03d}/{len(train_loader):03d}\"\n",
    "              f\" | Train Loss: {loss:.2f}\")\n",
    "\n",
    "    model.eval()\n",
    "    # Insert optional model evaluation code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723a368-4166-4b3a-baea-f50e56bc28a4",
   "metadata": {},
   "source": [
    "### Now that the model is trained I'm going to make some predictions with it and look at how it represents the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff2d5114-a9a0-42fd-98e8-b40d7bd4cf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.8569, -4.1618],\n",
      "        [ 2.5382, -3.7548],\n",
      "        [ 2.0944, -3.1820],\n",
      "        [-1.4814,  1.4816],\n",
      "        [-1.7176,  1.7342]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_train)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f82a89c7-3532-40bf-9fdd-1e60d6080652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9991, 0.0009],\n",
      "        [0.9982, 0.0018],\n",
      "        [0.9949, 0.0051],\n",
      "        [0.0491, 0.9509],\n",
      "        [0.0307, 0.9693]])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)  # Make outputs more legible\n",
    "probas = torch.softmax(outputs, dim=1)\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00b3e178-d714-433c-82b4-7143ce951ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.argmax(probas, dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06ff49ae-4b74-4188-8c89-a9cc8bed74c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# We can apply the argmax function to the logits (outputs) directly\n",
    "predictions = torch.argmax(outputs, dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6d8a377-2275-42ff-8175-8c18dfa30d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d2104b1-a6a9-4800-a3f3-bbc0539a6d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(predictions == y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d4dd33-c7de-42ab-8b77-d21e3afdaa03",
   "metadata": {},
   "source": [
    "### Creating a function to generalize the concept of model accuracy and account for arbitrarily large datasets by computing correctness in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6d0e687-f9dd-4e24-bcf6-d264ac76d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "    \n",
    "    model = model.eval()\n",
    "    correct = 0.0\n",
    "    total_examples = 0\n",
    "\n",
    "    for idx, (features, labels) in enumerate(dataloader):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(features)\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        compare = labels == predictions      # Returns a tensor of True/False values depending on whether the labels match\n",
    "        correct += torch.sum(compare)        # Count the number of True values (Since compare is a Tensor correct's type is promoted to a Tensor following the calculation to preserve Tensor properties)\n",
    "        total_examples += len(compare)\n",
    "\n",
    "    return (correct / total_examples).item() # The fraction of correct prediction, a value between 0 and 1. .item() returns the value of the tensor as a Python float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0cd051c-d4f6-40fd-b9de-ef6bd2044748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(compute_accuracy(model, train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54a899b9-6876-4df6-b0b9-769770d5f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(compute_accuracy(model, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06870fa-b992-484f-be9c-7a62de139bb6",
   "metadata": {},
   "source": [
    "### Seeing how to save a model's parameters to the disk and load a saved models parameters into a starting model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8a2fdd9-e062-4064-a304-141b7f65efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\") # \"model.pth\" can be any arbitrary name and file ending, however, .pth and .pt are convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5647c80f-b72b-43f0-ab10-79b9887a27cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(2, 2)\n",
    "model.load_state_dict(torch.load(\"model.pth\")) # An instance of the model in memory is required to apply the saved parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a46b861-6560-434b-b4f1-9755b4169f3b",
   "metadata": {},
   "source": [
    "### Exploring how to optimize performance with GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29cef689-930b-4d27-88b4-587cbfd5356c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if the version of PyTorch has GPU compatability\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df3124cb-3fae-42bb-81de-5401f8a0a58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "tensor_1 = torch.tensor([1., 2., 3.])\n",
    "tensor_2 = torch.tensor([4., 5., 6.])\n",
    "print(tensor_1 + tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd188c73-8fe9-4be4-ad41-8f29192abdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tensor_1 = tensor_1.to(\"cuda\")  # Changing datatype of tensor_1; can specify which GPU to locate tensor on through .to(\"cuda:0\") or .to(\"cuda:1\")\n",
    "tensor_2 = tensor_2.to(\"cuda\")\n",
    "print(tensor_1 + tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8b7b3c3-fdf5-4a42-ac74-f2e8bed32dce",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# NOTE: This cell is intended to return an error to see what happens when tensors are on different devices\u001b[39;00m\n\u001b[0;32m      2\u001b[0m tensor_1 \u001b[38;5;241m=\u001b[39m tensor_1\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \u001b[38;5;66;03m# All tensors used in a computation must be on the same device or they will fail\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tensor_1 \u001b[38;5;241m+\u001b[39m tensor_2)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# NOTE: This cell is intended to return an error to see what happens when tensors are on different devices\n",
    "tensor_1 = tensor_1.to(\"cpu\")   # All tensors used in a computation must be on the same device or they will fail\n",
    "print(tensor_1 + tensor_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb523f4-633b-45c4-a16c-5e5d9e6bf222",
   "metadata": {},
   "source": [
    "### Since what I'm using to test my Neural Network is a small dataset we won't notice an increase in performance because of the transfer cost from CPU to GPU. \n",
    "### However, this will be usefull when training deep neural networks, especially LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a408e3fe-db49-41da-b66a-6ee6a0de8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") # Defines a device variable that defaults to a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44c22683-a317-4e37-bae6-fcb019692d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Make the device able to run on CPU if GPU not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f72a7239-5548-44fc-ac29-2b105dba932f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndevice = torch.device(\\n    \"mps\" if torch.backends.mps.is_available() else \"cpu\"\\n)\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following code is for Mac's which an Apple Silicon chip (like the M1, M2, M3, and newer models)\n",
    "\"\"\"\n",
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af456f37-2897-4e55-9b9c-f96e3a18faa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/003 | Batch 001/002 | Train Loss: 0.75\n",
      "Epoch: 001/003 | Batch 002/002 | Train Loss: 0.65\n",
      "Epoch: 002/003 | Batch 001/002 | Train Loss: 0.44\n",
      "Epoch: 002/003 | Batch 002/002 | Train Loss: 0.13\n",
      "Epoch: 003/003 | Batch 001/002 | Train Loss: 0.03\n",
      "Epoch: 003/003 | Batch 002/002 | Train Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(num_inputs=2, num_outputs=2) # The toy dataset has 2 features and 2 classes\n",
    "\n",
    "model = model.to(device)                           # Transfers the model onto the GPU\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=0.5                     # The optimizer needs to know which parameters to optimize\n",
    ")\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "        features, labels = features.to(device), labels.to(device) # Transfers the data onto the GPU\n",
    "        logits = model(features)\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()                     # Sets the gradients from the previous round to 0 to prevent unintended gradient accumulation\n",
    "        loss.backward()                           # Computes the gradients of the loss given the model parameters\n",
    "        optimizer.step()                          # The optimizer used the gradients to update the model parameters\n",
    "\n",
    "        ## LOGGING\n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
    "              f\" | Batch {batch_idx+1:03d}/{len(train_loader):03d}\"\n",
    "              f\" | Train Loss: {loss:.2f}\")\n",
    "\n",
    "    model.eval()\n",
    "    # Insert optional model evaluation code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351d34a1-3ea0-4626-85ed-bcf8922a380f",
   "metadata": {},
   "source": [
    "### Training with multiple GPUs\n",
    "\n",
    "I will be experimenting with a Distributed Data Parallel (DDP) strategy for utilizing multiple GPUs. However, DDP does not function properly within interactivePython environments like Jupyter notebooks, as they dont handle multiprocessing in the same way that a standalone Python script does. \n",
    "\n",
    "Therefore, the following code of my experimentation will be executed as a script as DDp needs to spawn multiple processes, and each process should have its own Python interpreter instance.\n",
    "\n",
    "The code will be located at the following link in my GitHub repo for this project: https://github.com/Plehndm/LLM_From_Scratch/blob/main/DDP_Multiprocessing_Test.py\n",
    "\n",
    "As I am doing this on a Windows laptop (which is not best suited for DDP) if another windows user should attempt to run this you will likley run into issues as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d6c24-f738-4a7f-8300-06c66aca2094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
